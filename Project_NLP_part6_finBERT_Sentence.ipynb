{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/claire/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_pretrained_bert.modeling import BertForSequenceClassification\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertConfig\n",
    "from bertModel import BertClassification, dense_opt\n",
    "#from datasets import text_dataset, financialPhraseBankDataset\n",
    "import argparse\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0:'neutral', 1:'positive',2:'negative'}\n",
    "num_labels= len(labels)\n",
    "vocab = \"finance-uncased\"\n",
    "vocab_path = 'analyst_tone/vocab'\n",
    "pretrained_weights_path = \"analyst_tone/pretrained_weights\" # this is pre-trained FinBERT weights\n",
    "fine_tuned_weight_path = \"analyst_tone/fine_tuned.pth\"      # this is fine-tuned FinBERT weights\n",
    "max_seq_length=256\n",
    "device='gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claire/Desktop/Rebellion Project/finbert/bertModel.py:31: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  nn.init.xavier_normal(self.classifier.weight)\n"
     ]
    }
   ],
   "source": [
    "model = BertClassification(weight_path= pretrained_weights_path, num_labels=num_labels, vocab=vocab)\n",
    "tokenizer = BertTokenizer(vocab_file = vocab_path, do_lower_case = True, do_basic_tokenize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, mkldnn, opengl, opencl, ideep, hip, msnpu, xla device type at start of device string: gpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-20157d3a1ef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfine_tuned_weight_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, mkldnn, opengl, opencl, ideep, hip, msnpu, xla device type at start of device string: gpu"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(fine_tuned_weight_path, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer(vocab_file = vocab_path, do_lower_case = True, do_basic_tokenize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finbert(sent):\n",
    "    tokenized_sent = tokenizer.tokenize(sent)\n",
    "    if len(tokenized_sent) > max_seq_length:\n",
    "        tokenized_sent = tokenized_sent[:max_seq_length]\n",
    "    \n",
    "    ids_review  = tokenizer.convert_tokens_to_ids(tokenized_sent)\n",
    "    mask_input = [1]*len(ids_review)        \n",
    "    padding = [0] * (max_seq_length - len(ids_review))\n",
    "    ids_review += padding\n",
    "    mask_input += padding\n",
    "    input_type = [0]*max_seq_length\n",
    "    \n",
    "    input_ids = torch.tensor(ids_review).to(device).reshape(-1, 256)\n",
    "    attention_mask =  torch.tensor(mask_input).to(device).reshape(-1, 256)\n",
    "    token_type_ids = torch.tensor(input_type).to(device).reshape(-1, 256)\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(input_ids, token_type_ids, attention_mask)\n",
    "        outputs = F.softmax(outputs,dim=1)\n",
    "        return labels[torch.argmax(outputs).item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticker and cik table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "ticker_library = pd.read_csv('SHARADAR_TICKERS_6cc728d11002ab9cb99aa8654a6b9f4e.csv')\n",
    "ticker_selected = pd.read_csv('SP500_component_stocks.csv',header = None)\n",
    "ticker_selected.columns = ['name','ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticker_cik(file):\n",
    "    return str(file)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_library['cik'] = ticker_library['secfilings'].apply(ticker_cik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_cik_df = ticker_library[['ticker', 'cik']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>cik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>0001675149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAB</td>\n",
       "      <td>0001066808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAGY</td>\n",
       "      <td>0001182802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAP</td>\n",
       "      <td>0001611787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker         cik\n",
       "0      A  0001090872\n",
       "1     AA  0001675149\n",
       "2   AAAB  0001066808\n",
       "3  AAAGY  0001182802\n",
       "4   AAAP  0001611787"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_cik_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read 10-K and 10-Q files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store data using dictionary\n",
    "all_data = {}\n",
    "tenK = []\n",
    "tenQ = []\n",
    "tenKdate = []\n",
    "tenQdate = []\n",
    "tenKCik = []\n",
    "tenQCik = []\n",
    "tenKsector = []\n",
    "tenQsector = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'Correct Scrapping Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "industries = os.listdir(base_path)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Financials', 'Health', 'IT', 'Communication', 'ConsumerDiscretionary']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for industry in industries:\n",
    "    files = os.listdir(base_path + \"/\" + industry + '/10_k')\n",
    "    if '.DS_Store' in files:\n",
    "        files.remove('.DS_Store')\n",
    "    \n",
    "    for file in files:\n",
    "        path_10k = os.listdir(base_path + '/' + industry + '/10_k' + \"/\" + file + '/grabbed_text')\n",
    "        #print(path_10k)\n",
    "        if '.DS_Store' in path_10k:\n",
    "            path_10k.remove('.DS_Store')\n",
    "        for report in path_10k:\n",
    "            f = open(base_path + '/' + industry + '/10_k' + \"/\" + file + '/grabbed_text/' + str(report), \"r\")\n",
    "            text = f.read().lower()\n",
    "            date = report[-14:-4]\n",
    "            cik = report[:10]\n",
    "            tenK.append(text)\n",
    "            tenKdate.append(date)\n",
    "            tenKCik.append(cik)\n",
    "            tenKsector.append(industry)\n",
    "        \n",
    "        path_10q = os.listdir(base_path + '/' + industry + '/10_q' + \"/\" + file + '/grabbed_text')\n",
    "        if '.DS_Store' in path_10q:\n",
    "            path_10q.remove('.DS_Store')\n",
    "        for report in path_10q:\n",
    "            f = open(base_path + '/' + industry + '/10_q' + \"/\" + file + '/grabbed_text/' + str(report), \"r\")\n",
    "            text = f.read().lower()\n",
    "            date = report[-14:-4]\n",
    "            cik = report[:10]\n",
    "            tenQ.append(text)\n",
    "            tenQdate.append(date)\n",
    "            tenQCik.append(cik)\n",
    "            tenQsector.append(industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = len(tenK)\n",
    "l2 = len(tenQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1892"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences_10k = pd.DataFrame(columns = ['sentence', 'Date', 'Cik'])\n",
    "for i in range(l1):\n",
    "    sentences = pd.DataFrame(nltk.tokenize.sent_tokenize(tenK[i]), columns = ['sentence'])\n",
    "    sentences['Date'] = tenKdate[i]\n",
    "    sentences['Cik'] = tenKCik[i]\n",
    "    sentences['Sector'] = tenKsector[i]\n",
    "    #print(i)\n",
    "    sentences['Company'] = list(ticker_cik_df[ticker_cik_df['cik'] == tenKCik[i]].ticker)[0]\n",
    "    all_sentences_10k = pd.concat([all_sentences_10k, sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences_10k['File'] = '10-K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cik</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Company</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item 7. management's discussion and analysis o...</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the discussion should be read in conjunction w...</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forward-looking statements include, but are no...</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forward-looking statements are made based upon...</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>such forward-looking statements are not guaran...</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>see effect of exchange rates for additional ...</td>\n",
       "      <td>2008-02-11</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>investment risk as of december 31, 2007, our r...</td>\n",
       "      <td>2008-02-11</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>the fair values of our investments are subject...</td>\n",
       "      <td>2008-02-11</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>based on the fair value of the publicly-traded...</td>\n",
       "      <td>2008-02-11</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>42 table of contents</td>\n",
       "      <td>2008-02-11</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332765 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence        Date         Cik  \\\n",
       "0   item 7. management's discussion and analysis o...  2018-02-09  0001126328   \n",
       "1   the discussion should be read in conjunction w...  2018-02-09  0001126328   \n",
       "2   forward-looking statements include, but are no...  2018-02-09  0001126328   \n",
       "3   forward-looking statements are made based upon...  2018-02-09  0001126328   \n",
       "4   such forward-looking statements are not guaran...  2018-02-09  0001126328   \n",
       "..                                                ...         ...         ...   \n",
       "22  see effect of exchange rates for additional ...  2008-02-11  0001018724   \n",
       "23  investment risk as of december 31, 2007, our r...  2008-02-11  0001018724   \n",
       "24  the fair values of our investments are subject...  2008-02-11  0001018724   \n",
       "25  based on the fair value of the publicly-traded...  2008-02-11  0001018724   \n",
       "26                               42 table of contents  2008-02-11  0001018724   \n",
       "\n",
       "                   Sector Company  File  \n",
       "0              Financials     PFG  10-K  \n",
       "1              Financials     PFG  10-K  \n",
       "2              Financials     PFG  10-K  \n",
       "3              Financials     PFG  10-K  \n",
       "4              Financials     PFG  10-K  \n",
       "..                    ...     ...   ...  \n",
       "22  ConsumerDiscretionary    AMZN  10-K  \n",
       "23  ConsumerDiscretionary    AMZN  10-K  \n",
       "24  ConsumerDiscretionary    AMZN  10-K  \n",
       "25  ConsumerDiscretionary    AMZN  10-K  \n",
       "26  ConsumerDiscretionary    AMZN  10-K  \n",
       "\n",
       "[332765 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences_10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences_10q = pd.DataFrame(columns = ['sentence', 'Date', 'Cik'])\n",
    "for i in range(l2):\n",
    "    sentences = pd.DataFrame(nltk.tokenize.sent_tokenize(tenQ[i]), columns = ['sentence'])\n",
    "    sentences['Date'] = tenQdate[i]\n",
    "    sentences['Cik'] = tenQCik[i]\n",
    "    sentences['Sector'] = tenQsector[i]\n",
    "    sentences['Company'] = list(ticker_cik_df[ticker_cik_df['cik'] == tenQCik[i]].ticker)[0]\n",
    "    all_sentences_10q = pd.concat([all_sentences_10q, sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cik</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Company</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discussion and analysis of financial condition...</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this estimate excludes the impact of any poten...</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the selection of a 10% unfavorable change in t...</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>our exposure will change as a result of change...</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>use of derivatives to manage equity risk.</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>based on the outstanding 6.875% peacs princip...</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>assuming the u.s. dollar weakens against the e...</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>investment risk as of june 30, 2004, our recor...</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>the fair values of our investments are subject...</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>based on the fair value of the publicly-traded...</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678711 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence        Date         Cik  \\\n",
       "0   discussion and analysis of financial condition...  2017-08-02  0001126328   \n",
       "1   this estimate excludes the impact of any poten...  2017-08-02  0001126328   \n",
       "2   the selection of a 10% unfavorable change in t...  2017-08-02  0001126328   \n",
       "3   our exposure will change as a result of change...  2017-08-02  0001126328   \n",
       "4           use of derivatives to manage equity risk.  2017-08-02  0001126328   \n",
       "..                                                ...         ...         ...   \n",
       "17  based on the outstanding 6.875% peacs princip...  2004-07-23  0001018724   \n",
       "18  assuming the u.s. dollar weakens against the e...  2004-07-23  0001018724   \n",
       "19  investment risk as of june 30, 2004, our recor...  2004-07-23  0001018724   \n",
       "20  the fair values of our investments are subject...  2004-07-23  0001018724   \n",
       "21  based on the fair value of the publicly-traded...  2004-07-23  0001018724   \n",
       "\n",
       "                   Sector Company  File  \n",
       "0              Financials     PFG  10-Q  \n",
       "1              Financials     PFG  10-Q  \n",
       "2              Financials     PFG  10-Q  \n",
       "3              Financials     PFG  10-Q  \n",
       "4              Financials     PFG  10-Q  \n",
       "..                    ...     ...   ...  \n",
       "17  ConsumerDiscretionary    AMZN  10-Q  \n",
       "18  ConsumerDiscretionary    AMZN  10-Q  \n",
       "19  ConsumerDiscretionary    AMZN  10-Q  \n",
       "20  ConsumerDiscretionary    AMZN  10-Q  \n",
       "21  ConsumerDiscretionary    AMZN  10-Q  \n",
       "\n",
       "[678711 rows x 6 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences_10q['File'] = '10-Q'\n",
    "all_sentences_10q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = pd.concat([all_sentences_10k, all_sentences_10q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cik</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Company</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item 7. management's discussion and analysis o...</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the discussion should be read in conjunction w...</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forward-looking statements include, but are no...</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>forward-looking statements are made based upon...</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>such forward-looking statements are not guaran...</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>0001126328</td>\n",
       "      <td>Financials</td>\n",
       "      <td>PFG</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>based on the outstanding 6.875% peacs princip...</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>assuming the u.s. dollar weakens against the e...</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>investment risk as of june 30, 2004, our recor...</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>the fair values of our investments are subject...</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>based on the fair value of the publicly-traded...</td>\n",
       "      <td>2004-07-23</td>\n",
       "      <td>0001018724</td>\n",
       "      <td>ConsumerDiscretionary</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011476 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence        Date         Cik  \\\n",
       "0   item 7. management's discussion and analysis o...  2018-02-09  0001126328   \n",
       "1   the discussion should be read in conjunction w...  2018-02-09  0001126328   \n",
       "2   forward-looking statements include, but are no...  2018-02-09  0001126328   \n",
       "3   forward-looking statements are made based upon...  2018-02-09  0001126328   \n",
       "4   such forward-looking statements are not guaran...  2018-02-09  0001126328   \n",
       "..                                                ...         ...         ...   \n",
       "17  based on the outstanding 6.875% peacs princip...  2004-07-23  0001018724   \n",
       "18  assuming the u.s. dollar weakens against the e...  2004-07-23  0001018724   \n",
       "19  investment risk as of june 30, 2004, our recor...  2004-07-23  0001018724   \n",
       "20  the fair values of our investments are subject...  2004-07-23  0001018724   \n",
       "21  based on the fair value of the publicly-traded...  2004-07-23  0001018724   \n",
       "\n",
       "                   Sector Company  File  \n",
       "0              Financials     PFG  10-K  \n",
       "1              Financials     PFG  10-K  \n",
       "2              Financials     PFG  10-K  \n",
       "3              Financials     PFG  10-K  \n",
       "4              Financials     PFG  10-K  \n",
       "..                    ...     ...   ...  \n",
       "17  ConsumerDiscretionary    AMZN  10-Q  \n",
       "18  ConsumerDiscretionary    AMZN  10-Q  \n",
       "19  ConsumerDiscretionary    AMZN  10-Q  \n",
       "20  ConsumerDiscretionary    AMZN  10-Q  \n",
       "21  ConsumerDiscretionary    AMZN  10-Q  \n",
       "\n",
       "[1011476 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Financials', 'Health', 'IT', 'Communication',\n",
       "       'ConsumerDiscretionary'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences['Sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences['Company'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AMD', 'LRCX', 'NLOK', 'PAYC', 'CTSH', 'ADS', 'AAPL', 'INTC',\n",
       "       'MSFT', 'WU'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences[all_sentences['Sector'] == 'IT']['Company'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences.to_csv(\"Sentences_all.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWTR_pivot.to_csv('TWTR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWTR.to_csv('TWTR_sentence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
